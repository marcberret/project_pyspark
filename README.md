<h1 align="center">Projet/Support PySpark</h1>

Ce notebook a pour objectif de faciliter la compréhension de l'architecture de Spark et l'utilisation des fonctionnalités de l'API PySpark dans un environnement Databricks. 

Il se divise en trois sections principales :
- Concepts de base de Spark : introduction des concepts fondamentaux en expliquant SparkContext, SparkSession ainsi que les Resilient Distributed Datasets (RDD)
- Manipulation des données avec Spark DataFrame : lecture et collecte de fichiers (.txt, .csv, .json) en DataFrame Spark et présentation des principales transformations et actions réalisables.
- Utilisation de Spark SQL 

## Lien

- [**Code**](https://github.com/marcberret/project_pyspark/blob/main/main.ipynb)
